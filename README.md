# üß† MindLoop Backend

Backend standalone para sistema de classifica√ß√£o de eventos SMS usando **LATS-P** (Language Agent Tree Search - Probabilistic) com **HITL** (Human-in-the-Loop).

---

## üìã Sobre

API REST desenvolvida em **FastAPI** para classifica√ß√£o inteligente de eventos SMS da ANP (Ag√™ncia Nacional do Petr√≥leo).

Este projeto √© **completamente independente**, sem frontend, pronto para deploy **serverless** (Vercel) ou **containerizado** (Docker/K8s).

---

## üöÄ Features

- ‚úÖ **LATS-P**: Algoritmo de busca em √°rvore probabil√≠stica
- ‚úÖ **HITL**: Human-in-the-loop com detec√ß√£o de entropia
- ‚úÖ **Serverless Mode**: Deploy otimizado para Vercel (< 250 MB)
- ‚úÖ **Full Mode**: Modo completo com RAG/FAISS para ambientes locais
- ‚úÖ **Configura√ß√£o 100% ENV**: Sem depend√™ncia de `config.ini`
- ‚úÖ **Logging Estruturado**: JSON logs para produ√ß√£o
- ‚úÖ **CORS Configur√°vel**: Integra√ß√£o com frontend
- ‚úÖ **OpenAPI Docs**: Swagger UI autom√°tico

---

## üèóÔ∏è Arquitetura

```
mindloop-backend/
‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îú‚îÄ‚îÄ main.py              # Aplica√ß√£o FastAPI
‚îÇ   ‚îú‚îÄ‚îÄ api/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ models.py        # Modelos Pydantic
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ routes.py        # Rotas da API
‚îÇ   ‚îú‚îÄ‚îÄ core/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ config.py        # Configura√ß√£o via ENV
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ logging_setup.py # Setup de logging
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ errors.py        # Exception handlers
‚îÇ   ‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ lats_service.py  # L√≥gica LATS-P
‚îÇ   ‚îî‚îÄ‚îÄ lats_sistema/        # Engine LATS completo
‚îú‚îÄ‚îÄ api/
‚îÇ   ‚îî‚îÄ‚îÄ index.py             # Entrypoint Vercel
‚îú‚îÄ‚îÄ requirements.txt         # Deps serverless
‚îú‚îÄ‚îÄ requirements-full.txt    # Deps full (RAG/FAISS)
‚îú‚îÄ‚îÄ .env.example             # Template de vari√°veis
‚îú‚îÄ‚îÄ vercel.json              # Config Vercel
‚îî‚îÄ‚îÄ README.md
```

---

## ‚öôÔ∏è Configura√ß√£o

### 1. Pr√©-requisitos

- **Python** 3.10+
- **pip** ou **uv**

### 2. Instala√ß√£o

#### Modo Serverless (produ√ß√£o)

```bash
# Clone o reposit√≥rio
git clone <seu-repositorio>
cd mindloop-backend

# Crie virtual environment
python -m venv .venv
source .venv/bin/activate  # Linux/Mac
# .venv\Scripts\activate   # Windows

# Instale depend√™ncias m√≠nimas
pip install -r requirements.txt
```

#### Modo Full (desenvolvimento com RAG/FAISS)

```bash
# Instale depend√™ncias completas
pip install -r requirements-full.txt
```

### 3. Vari√°veis de Ambiente

Crie `.env` baseado em `.env.example`:

```bash
cp .env.example .env
```

**Configura√ß√£o m√≠nima (obrigat√≥ria)**:

```env
# .env
OPENAI_API_KEY=sk-proj-...
SERVERLESS_MODE=1
CORS_ORIGINS=http://localhost:3000
```

**Configura√ß√£o completa**:

```env
# Runtime
ENV=development
DEBUG=false

# Modes
SERVERLESS_MODE=1     # 0 = full mode, 1 = serverless
FAST_MODE=0           # 0 = normal, 1 = economia de tokens

# OpenAI
OPENAI_API_KEY=sk-proj-...
OPENAI_CHAT_MODEL=gpt-4o-mini
OPENAI_EMBED_MODEL=text-embedding-3-small

# Azure (opcional)
# AZURE_API_KEY=...
# AZURE_ENDPOINT=https://...

# CORS
CORS_ORIGINS=http://localhost:3000,http://localhost:3001

# Features
USE_HYDE=0
USE_RAG=0
SKIP_RAG_DEFAULT=1

# Logging
LOG_LEVEL=INFO
```

---

## üèÉ Executando Localmente

### Desenvolvimento

```bash
# Ativar virtual environment
source .venv/bin/activate

# Rodar servidor
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

Acesse:
- **API**: http://localhost:8000
- **Docs (Swagger)**: http://localhost:8000/docs
- **ReDoc**: http://localhost:8000/redoc

### Produ√ß√£o (local)

```bash
uvicorn app.main:app --host 0.0.0.0 --port 8000 --workers 4
```

---

## üåê Deploy

### Vercel (Serverless)

#### Via Dashboard

1. Acesse [vercel.com](https://vercel.com)
2. Import reposit√≥rio
3. Configure vari√°veis de ambiente:

```
SERVERLESS_MODE=1
OPENAI_API_KEY=sk-proj-...
OPENAI_CHAT_MODEL=gpt-4o-mini
CORS_ORIGINS=https://seu-frontend.vercel.app
```

4. Deploy

#### Via CLI

```bash
# Instalar Vercel CLI
npm install -g vercel

# Login
vercel login

# Deploy
vercel --prod
```

**Importante**: O Vercel usa `api/index.py` como entrypoint.

---

### Docker

#### Modo Serverless

```dockerfile
FROM python:3.10-slim

WORKDIR /app

COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

COPY app/ ./app/
COPY api/ ./api/

ENV SERVERLESS_MODE=1
ENV PYTHONPATH=.

CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000"]
```

```bash
docker build -t mindloop-backend .
docker run -p 8000:8000 --env-file .env mindloop-backend
```

#### Modo Full (com RAG)

```dockerfile
FROM python:3.10-slim

WORKDIR /app

COPY requirements-full.txt .
RUN pip install --no-cache-dir -r requirements-full.txt

COPY app/ ./app/
COPY api/ ./api/

ENV SERVERLESS_MODE=0
ENV PYTHONPATH=.

CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000"]
```

---

### Outras Plataformas

**Railway**:
```bash
railway login
railway init
railway up
```

**Render**:
- Build Command: `pip install -r requirements.txt`
- Start Command: `uvicorn app.main:app --host 0.0.0.0 --port $PORT`

**AWS Lambda** (via Mangum):
```python
# api/lambda_handler.py
from mangum import Mangum
from app.main import app

handler = Mangum(app)
```

---

## üì° API Endpoints

### Health Check

```bash
GET /health
```

**Response**:
```json
{
  "status": "ok",
  "version": "1.0.0",
  "mode": "serverless",
  "features": {
    "rag": false,
    "hyde": false,
    "serverless_mode": true,
    "fast_mode": false
  }
}
```

---

### Classifica√ß√£o de Evento

```bash
POST /predict
Content-Type: application/json

{
  "descricao_evento": "Vazamento de √≥leo no mar"
}
```

**Response (sem HITL)**:
```json
{
  "hitl_required": false,
  "final": {
    "categoria_final": "Ambiental",
    "justificativa": "...",
    "log_prob": -0.5
  },
  "confianca": {...},
  "resultado_formatado": {...},
  "state": {...}
}
```

**Response (com HITL)**:
```json
{
  "hitl_required": true,
  "hitl_metadata": {
    "opcoes": [
      {"id": "node_123", "label": "Ambiental", "prob": 0.35},
      {"id": "node_124", "label": "Operacional", "prob": 0.33}
    ],
    "entropia": 1.45
  },
  "state": {...}
}
```

---

### Continua√ß√£o HITL

```bash
POST /hitl/continue
Content-Type: application/json

{
  "state": {...},
  "selected_child": "node_123",
  "justification": "An√°lise manual"
}
```

**Response**:
```json
{
  "hitl_required": false,
  "final": {
    "categoria_final": "Ambiental",
    "justificativa": "An√°lise manual",
    "log_prob": -0.3
  },
  "confianca": {...},
  "resultado_formatado": {...},
  "state": {...}
}
```

---

## üîß Modos de Opera√ß√£o

### Serverless Mode (`SERVERLESS_MODE=1`)

**Otimizado para Vercel/Lambda**:
- ‚ùå RAG/FAISS desabilitado
- ‚ùå Sem numpy/pandas
- ‚úÖ LATS-P completo
- ‚úÖ HITL completo
- ‚úÖ Bundle < 100 MB
- ‚úÖ Cold start ~2-3s

**Use quando**:
- Deploy em Vercel/Lambda
- Limite de bundle size
- N√£o precisa de busca vetorial

### Full Mode (`SERVERLESS_MODE=0`)

**Completo com RAG/FAISS**:
- ‚úÖ RAG pipeline completo
- ‚úÖ FAISS para busca vetorial
- ‚úÖ Mem√≥ria epis√≥dica
- ‚úÖ HyDE (opcional)
- ‚ö†Ô∏è Bundle ~300-400 MB

**Use quando**:
- Ambiente local/container
- Precisa de RAG/contexto normativo
- Tem recursos suficientes

---

## üß™ Testes

### Teste Manual

```bash
# Health check
curl http://localhost:8000/health

# Predict
curl -X POST http://localhost:8000/predict \
  -H "Content-Type: application/json" \
  -d '{"descricao_evento": "Vazamento de √≥leo"}'
```

### Testes Automatizados

```bash
# Install dev dependencies
pip install pytest pytest-cov httpx

# Run tests
pytest tests/ -v

# Coverage
pytest tests/ --cov=app --cov-report=html
```

---

## üîç Troubleshooting

### Erro: `ValidationError: OPENAI_API_KEY field required`

**Causa**: Vari√°vel de ambiente n√£o configurada

**Solu√ß√£o**:
```bash
export OPENAI_API_KEY=sk-proj-...
# ou adicione no .env
```

---

### Erro: `ModuleNotFoundError: No module named 'faiss'`

**Causa**: Tentando usar RAG em serverless mode

**Solu√ß√£o**:
```env
# .env
SERVERLESS_MODE=1
USE_RAG=0
```

Ou instale depend√™ncias completas:
```bash
pip install -r requirements-full.txt
```

---

### Erro: `CORS policy blocked`

**Causa**: Frontend n√£o est√° nas origins permitidas

**Solu√ß√£o**:
```env
# .env
CORS_ORIGINS=http://localhost:3000,https://seu-frontend.vercel.app
```

---

### Bundle size excede 250 MB no Vercel

**Causa**: Depend√™ncias pesadas instaladas

**Solu√ß√£o**:
1. Confirme `SERVERLESS_MODE=1` em `vercel.json`
2. Use `requirements.txt` (n√£o `requirements-full.txt`)
3. Verifique `.vercelignore` est√° correto

---

## üìä M√©tricas Esperadas

| M√©trica | Serverless | Full |
|---------|-----------|------|
| **Bundle size** | ~80-100 MB | ~300-400 MB |
| **Cold start** | ~2-3s | ~5-10s |
| **Response time** | ~1-3s | ~2-5s |
| **Memory usage** | ~200-300 MB | ~500-800 MB |

---

## üîó Frontend

Este backend requer o frontend MindLoop para interface completa.

**Reposit√≥rio**: [mindloop-frontend](https://github.com/seu-usuario/mindloop-frontend)

**Configurar no frontend**:
```env
# Frontend .env.local
NEXT_PUBLIC_API_URL=http://localhost:8000
```

---

## üìù Licen√ßa

Este projeto √© privado e propriet√°rio.

---

## üë§ Autor

**Bernardo Puppim**

- GitHub: [@bernardopuppim](https://github.com/bernardopuppim)

---

## ü§ù Suporte

Para quest√µes ou problemas:

1. Verifique os logs: `LOG_LEVEL=DEBUG`
2. Confirme vari√°veis de ambiente
3. Teste `/health` endpoint
4. Revise a documenta√ß√£o em `/docs`

---

**Status**: ‚úÖ Produ√ß√£o pronto
**Vers√£o**: 1.0.0
**√öltima atualiza√ß√£o**: 2026-01-06
